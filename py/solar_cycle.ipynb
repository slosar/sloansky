{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord, get_moon, EarthLocation, ICRS, GCRS,AltAz\n",
    "from astropy.time import Time\n",
    "from astropy.io.fits.hdu.hdulist import HDUList\n",
    "from datetime import date\n",
    "from astral import Astral, Location\n",
    "from astropy.time import Time\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyfits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earliest date= 55176 or 12-11-2009\n",
      "latest date= 57520 or 05-12-2016\n"
     ]
    }
   ],
   "source": [
    "## Finding out which file years to download\n",
    "all_sky=pd.read_csv('objSKY.csv')\n",
    "all_sky.head()\n",
    "print('earliest date=', min(all_sky['MJD']), 'or 12-11-2009')\n",
    "print('latest date=', max(all_sky['MJD']), 'or 05-12-2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## To check for reading in the right file\n",
    "rand_files=('spec-3586-55181-0496.fits','spec-3586-55181-0788.fits','spec-3586-55181-0996.fits',\n",
    "            'spec-3761-55272-0008.fits','spec-10000-57346-0334.fits','spec-3761-55272-0475.fits',\n",
    "            'spec-10000-57346-0659.fits','spec-5478-56014-0654.fits','spec-10000-57346-0955.fits',\n",
    "            'spec-5478-56014-0716.fits','spec-10000-57346-0994.fits')\n",
    "\n",
    "## To look for patterns\n",
    "inseq_files=('spec-3663-55176-0010.fits','spec-3663-55176-0012.fits','spec-3663-55176-0020.fits',\n",
    "             'spec-3663-55176-0024.fits','spec-3663-55176-0036.fits','spec-3663-55176-0038.fits',\n",
    "             'spec-3663-55176-0048.fits','spec-3663-55176-0052.fits','spec-3663-55176-0056.fits',\n",
    "             'spec-3663-55176-0068.fits','spec-3663-55176-0075.fits','spec-3663-55176-0078.fits',\n",
    "             'spec-3663-55176-0090.fits','spec-3663-55176-0094.fits','spec-3663-55176-0096.fits',\n",
    "             'spec-3663-55176-0108.fits','spec-3663-55176-0112.fits','spec-3663-55176-0114.fits',\n",
    "             'spec-3663-55176-0128.fits','spec-3663-55176-0134.fits')\n",
    "\n",
    "solar_files=('g2009.txt','g2010.txt','g2011.txt','g2012.txt','g2013.txt','g2014.txt','g2015.txt','g2016.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting MJDs from fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a) first load all files and convert all dates into mjds.\n",
    "def get_mjd(file):\n",
    "    da=pyfits.open(file)\n",
    "    return (da[4].header['MJD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55181\n",
      "55181\n",
      "55181\n",
      "55272\n",
      "57345\n",
      "55272\n",
      "57345\n",
      "56014\n",
      "57345\n",
      "56014\n",
      "57345\n"
     ]
    }
   ],
   "source": [
    "for i in rand_files:\n",
    "    print(get_mjd(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing by date and sum duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_subs(lst_of_lsts):\n",
    "    res = []\n",
    "    for row in lst_of_lsts:\n",
    "        for i, resrow in enumerate(res):\n",
    "            if row[:3]==resrow[:3]:\n",
    "                res[i] += row[1:]\n",
    "                break\n",
    "        else:\n",
    "            res.append(row)\n",
    "    return (res)\n",
    "## Merges lists, but does not remove first 3 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f2(seq): \n",
    "    # order preserving\n",
    "    checked = []\n",
    "    for e in seq:\n",
    "        if e not in checked:\n",
    "            checked.append(e)\n",
    "    return checked\n",
    "## removes duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Function to organize mill. of sol. disk by date\n",
    "def organize_sum_dates(txt_file):\n",
    "    ## We only need year, month, day of month, and mill. of sol. disk\n",
    "    ## Cols         1-4    5-6      7-8               31-34\n",
    "    demo=list(chain.from_iterable((x[:4], x[4:6], x[6:10], x[31:34]) for x in open(txt_file).readlines()))\n",
    "    ## Organizing cols\n",
    "    str_list=[demo[i*4:i*4+4] for i in range(int(len(demo)/4))]\n",
    "    ## Converting to float\n",
    "    float_dates=[]\n",
    "    for k in range(len(str_list)):\n",
    "        float_dates.append([float(i) for i in str_list[k]])\n",
    "    b=([x[:4] for x in float_dates])\n",
    "    ve=merge_subs(b)\n",
    "    new=[]\n",
    "    summed_mills=[]\n",
    "    no_mills=[]\n",
    "    merged_lists=[]\n",
    "    for i in range(len(ve)):\n",
    "        new.append(f2(ve[i]))\n",
    "        summed_mills.append(sum(new[i][3:]))\n",
    "        no_mills.append(new[i][:3])\n",
    "        merged_lists.append(np.append(no_mills[i],summed_mills[i]).tolist())\n",
    "    return(merged_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2011.0, 1.0, 1.5, 405.0],\n",
       " [2011.0, 1.0, 2.5, 375.0],\n",
       " [2011.0, 1.0, 3.5, 517.0],\n",
       " [2011.0, 1.0, 4.5, 537.0],\n",
       " [2011.0, 1.0, 5.5, 381.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial=organize_sum_dates(solar_files[2])\n",
    "trial[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in solar_files:\n",
    "#    print(organize_by_date(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolated function from MJDs to mill of sol. disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#b) Then set up one massive interpolated function from mjds to mill of sol. disk\n",
    "## Pulling out cols of interest\n",
    "demo=list(chain.from_iterable((x[:4], x[4:6], x[6:10], x[31:34]) for x in open('g2010.txt').readlines()))\n",
    "## Organizing cols\n",
    "str_list=[demo[i*4:i*4+4] for i in range(int(len(demo)/4))]\n",
    "## Converting to float\n",
    "float_dates=[]\n",
    "for k in range(len(str_list)):\n",
    "    float_dates.append([float(i) for i in str_list[k]])\n",
    "b=([x[:4] for x in float_dates])\n",
    "ve=merge_subs(b)\n",
    "new=[]\n",
    "summed_mills=[]\n",
    "no_mills=[]\n",
    "merged_lists=[]\n",
    "for i in range(len(ve)):\n",
    "    new.append(f2(ve[i]))\n",
    "    summed_mills.append(sum(new[i][3:]))\n",
    "    no_mills.append(new[i][:3])\n",
    "    merged_lists.append(np.append(no_mills[i],summed_mills[i]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_lists[1][2]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010.0, 1.0, 5.5, 0.0] [2010.0, 1.0, 7.5, 67.0]\n",
      "67.0\n",
      "[2010.0, 1.0, 18.5, 21.0] [2010.0, 1.0, 20.5, 28.0]\n",
      "2010.0\n",
      "[2010.0, 3.0, 5.5, 11.0] [2010.0, 3.0, 10.5, 10.0]\n",
      "2010.0\n",
      "[2010.0, 4.0, 10.5, 1.0] [2010.0, 4.0, 12.5, 19.0]\n",
      "19.0\n",
      "[2010.0, 4.0, 14.5, 16.0] [2010.0, 4.0, 28.5, 18.0]\n",
      "2010.0\n",
      "[2010.0, 4.0, 28.5, 18.0] [2010.0, 4.0, 30.5, 33.0]\n",
      "2010.0\n",
      "[2010.0, 5.0, 8.5, 7.0] [2010.0, 5.0, 21.5, 56.0]\n",
      "2010.0\n",
      "[2010.0, 6.0, 14.5, 1.0] [2010.0, 6.0, 17.5, 15.0]\n",
      "15.0\n",
      "[2010.0, 6.0, 25.5, 0.0] [2010.0, 6.0, 27.5, 84.0]\n",
      "84.0\n",
      "[2010.0, 8.0, 20.5, 0.0] [2010.0, 8.0, 24.5, 12.0]\n",
      "12.0\n",
      "[2010.0, 9.0, 8.5, 0.0] [2010.0, 9.0, 11.5, 37.0]\n",
      "37.0\n",
      "[2010.0, 10.0, 5.5, 0.0] [2010.0, 10.0, 8.5, 0.0]\n",
      "0.0\n",
      "[2010.0, 12.0, 17.5, 0.0] [2010.0, 12.0, 25.5, 44.0]\n",
      "44.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(merged_lists)):\n",
    "    if merged_lists[i][2]!=merged_lists[i-1][2]+1 and merged_lists[i][1]==merged_lists[i-1][1]:#missing days in months\n",
    "        print(merged_lists[i-1], merged_lists[i])\n",
    "        print(np.interp(2.5,merged_lists[i-1], merged_lists[i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list_example=[[1,1,2016,212], [1,2,2016,170], [1,3,2016,150], [1,5,2016,96], [1,6,2016,150], [1,8,2016,321]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#zip(list_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
